---
title: "Physics-guided infrared spatiotemporal noise modeling based on hybrid neural representation"
authors:
- Chao Qu

author_notes:
- ""
- ""
date: "2024-10-23T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: ""

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article-journal"]

# Publication name and optional abbreviated publication name.
publication: "IEEE Sensors Journal [Under Review]"
publication_short: ""

abstract: Collecting real-world infrared noisy-clean video pairs to train deep video denoising networks is challenging; therefore, these networks typically rely on synthetic data generated from noise models. Existing models primarily focus on the spatial distribution of noise but often fail to accurately capture the complexity of temporal variations in infrared noise within dynamic scenes, which limits the performance of denoising networks. To address this issue, we propose an infrared spatiotemporal noise modeling framework (IRSTN) based on hybrid neural representation, which leverages unpaired video data to simulate real-world noise. The key of IRSTN lies in its independent and compact representation of the spatial and temporal distributions of noise. Specifically, IRSTN first obtains spatial embeddings by introducing physical-based noise prior to capture the spatial context of noise; secondly, it generates temporal embeddings using position encoding of the frame index to describe the temporal correlations of noise. Subsequently, IRSTN constructs hybrid neural representations of noise that deeply integrate spatial and temporal embeddings while implicitly modeling the complex spatiotemporal distribution of infrared noise through recurrent adversarial learning. Furthermore, by constraining the consistency of noise intensity in both the forward and backward recursions, it effectively suppresses temporal artifacts that may appear in the generated noisy videos. To validate the effectiveness of IRSTN, we collected a real-world infrared video denoising dataset for training and benchmarking. Qualitative experiments indicate that the infrared noise generated by IRSTN is highly similar to real noise in terms of spatiotemporal distribution. Extensive denoising experiments demonstrate that IRSTN endows infrared video denoising networks with highly competitive performance in real-world scenarios.

# Summary. An optional shortened abstract.
summary: We propose an infrared spatiotemporal noise modeling framework (IRSTN) based on hybrid neural representation, which leverages unpaired video data to simulate real-world noise.

tags:
  - noise modeling
  - video denoising
featured: false
featured1: true
# links:
# - name: ""
#   url: ""
# url_pdf: https://www.mdpi.com/1099-4300/26/3/209
# url_code: ''
# url_dataset: ''
# url_poster: ''
# url_project: ''
# url_slides: ''
# url_source: ''
# url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# image:
#   caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/jdD8gXaTZsc)'
#   focal_point: ""
#   preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: example
---

<!-- {{% callout note %}}
Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the *Slides* button to check out the example.
{{% /callout %}} -->

<!-- Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). -->
