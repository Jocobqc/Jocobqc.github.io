@article{Qu:26,
author = {Chao Qu and Jing Han and Haotian Yu and Xiaoyu Chen},
journal = {Opt. Express},
number = {3},
pages = {4949--4965},
publisher = {Optica Publishing Group},
title = {Prior-guided infrared spatiotemporal noise modeling based on a hybrid neural representation},
volume = {34},
month = {Feb},
year = {2026},
url = {https://opg.optica.org/oe/abstract.cfm?URI=oe-34-3-4949},
doi = {10.1364/OE.583048},
abstract = {Noise modeling of imaging sensors is a critical challenge in infrared vision applications. Existing noise modeling methods primarily focus on spatial distribution, making it difficult to accurately characterize temporal variations in infrared noise in dynamic scenes and thereby limiting the performance of video denoising algorithms. To address this problem, we construct an infrared video dataset that contains real indoor and outdoor scenes for noise modeling and algorithm evaluation. Based on this, we propose IRSTN, an infrared spatiotemporal noise modeling framework that synthesizes high-fidelity noise from unpaired data. Specifically, IRSTN incorporates noise priors to generate spatial embeddings that capture noise spatial context, and employs position encoding of frame indices to produce temporal embeddings that represent noise temporal correlations. Furthermore, IRSTN develops a hybrid neural representation of noise that deeply integrates spatial and temporal embeddings, implicitly modeling the spatiotemporal noise distribution via recurrent adversarial learning. Quantitative evaluations demonstrate that the infrared noise generated by IRSTN exhibits high consistency with real noise in spatiotemporal characteristics. Extensive denoising experiments show that IRSTN significantly improves the performance of video denoising networks in real-world scenes.},
}